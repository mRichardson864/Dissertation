{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "#Imports\n",
    "import pyarrow\n",
    "import feather\n",
    "import time\n",
    "import json\n",
    "import pandas\n",
    "import csv\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tables\n",
    "import numpy as np\n",
    "import pyarrow.feather as pf\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from datetime import datetime\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "from tables import *\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data to testDF\n",
    "path = 'all_april.feather'\n",
    "aprilDF = feather.read_dataframe(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sentiment array for april and may\n",
    "sentimentValuesApril = list([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the average sentiment value for each day in April\n",
    "tic = time.perf_counter()\n",
    "\n",
    "#create list holding sentiment values\n",
    "sentimentValuesApril = list([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "date = '-04-2020' #date stub for April 2020\n",
    "for i in range(0,30): #for each day\n",
    "    temp_date = date #reset the date variable\n",
    "    if (i < 9): #for single digit days, prepend a zero to the date\n",
    "        temp_date = '0' + str(i+1) + date\n",
    "    else: \n",
    "        temp_date = str(i+1) + date;\n",
    "        \n",
    "    condition = aprilDF['date'] == temp_date #filter dataframe to a specific day\n",
    "    for entry in aprilDF[condition]['sentiment']: #For each tweet for that day, add the sentiment to a running total\n",
    "        sentimentValuesApril[i] += entry\n",
    "    sentimentValuesApril[i] /= aprilDF[condition]['sentiment'].size #divide total by number of tweets\n",
    "    \n",
    "toc = time.perf_counter()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets the variable allSentimentValues to our loaded in data \n",
    "allSentimentValues = sentimentValuesApril\n",
    "print(len(allSentimentValues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list containing each date in april to be used for plotting our graphs\n",
    "dateListApril = aprilDF['date'].unique().tolist()\n",
    "i=0\n",
    "for date in dateListApril:\n",
    "    dateListApril[i] = str(date[0:5:1])\n",
    "    i += 1;\n",
    "\n",
    "\n",
    "\n",
    "totalDateList = dateListApril # + dateListMay\n",
    "\n",
    "print(totalDateList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in covid figures #Look at files for how data was gathered\n",
    "caseDF = pandas.read_csv('covidcases.csv', index_col=0)\n",
    "\n",
    "unitedStates = list(caseDF['US'])\n",
    "unitedStates = unitedStates[:44]\n",
    "unitedKingdom = list(caseDF['UK'])\n",
    "unitedKingdom = unitedKingdom[:44]\n",
    "unitedAll = [sum(t) for t in zip(unitedKingdom, unitedStates)]\n",
    "print(unitedStates)\n",
    "print(unitedKingdom)\n",
    "print(unitedAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the value of each value subtract the mean\n",
    "def calcVSM(offset, N, x, y):\n",
    "    xVSM = list()\n",
    "    yVSM = list()\n",
    "    productVSM = list()\n",
    "    for val in x[offset:offset+N]:\n",
    "        xVSM.append(val - np.mean(x[offset:offset+N]))\n",
    "    for val in y[:N]:\n",
    "        yVSM.append(val - np.mean(y[:N]))\n",
    "    for i in range(N):\n",
    "        productVSM.append(xVSM[i] * yVSM[i])\n",
    "        \n",
    "    return productVSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross correlation equation\n",
    "N = 30\n",
    "x = unitedAll\n",
    "y = allSentimentValues\n",
    "productVSM = calcVSM(0, N, x, y)\n",
    "r = (1/N) * ((sum(productVSM))/np.sqrt(np.var(x[:N]) * np.var(y[:N])))\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross corerlation for each offset up to two weeks\n",
    "N = 30 #number of days being looked at\n",
    "x = unitedAll\n",
    "\n",
    "y = allSentimentValues\n",
    "corrArray = list()\n",
    "for i in range(0,14,1):\n",
    "    productVSM = calcVSM(i, 30, x, y)\n",
    "    corrArray.append((1/(N)) * ((sum(productVSM))/np.sqrt(np.var(x[i:i+N]) * np.var(y[:N]))))\n",
    "corrArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set varaible to our desired dataset\n",
    "case_data = unitedAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix the formatting of the dates \n",
    "subDates = list()\n",
    "for date in totalDateList:\n",
    "    subDates.append(date[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the combined US and UK against sentiment\n",
    "sample_range = 30\n",
    "x = subDates[:sample_range]\n",
    "y = allSentimentValues[:sample_range]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y, 's-r', label = \"Average Sentiment Score\")\n",
    "\n",
    "ax.set_ylim(ymin=0)\n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(case_data[:sample_range], 'o-b', label = \"Number of new cases\")\n",
    "ax3.set_ylim(ymin=0)\n",
    "ax.xaxis.set_label_text(\"Date\")\n",
    "ax.yaxis.set_label_text(\"Average Sentiment Score\")\n",
    "ax3.yaxis.set_label_text(\"Number of cases\")\n",
    "lns = [ax, ax3]\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax3.legend(loc='lower right', bbox_to_anchor=(1.0, 0.1))\n",
    "fig.subplots_adjust(right=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the NCC ratio for a moving time lag\n",
    "x = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "y = corrArray\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y, 's-r', label=\"NCC\")\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "ax.xaxis.set_label_text(\"Offset (days)\")\n",
    "ax.yaxis.set_label_text(\"Correlation ratio\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph for Correlation of covid keyword to cases\n",
    "\n",
    "\n",
    "x = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "y = corrArray2\n",
    "#z = randomlist\n",
    "#plt.figure(figsize=(15,5))\n",
    "#plt.plot(x,y,z)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y, 's-r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph showing the difference in correlation between \n",
    "\n",
    "x = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "y = corrArray\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y, 's-r', label = 'sentiment')\n",
    "ax.legend(loc = 'center left')\n",
    "ax3 = ax.twinx()\n",
    "\n",
    "ax3.plot(corrArray2, 'o-b', label = \"covid keyword\")\n",
    "ax3.legend(loc = 'upper left')\n",
    "#fig.subplots_adjust(right=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up spacy matcher and choose pattern to test over dataframe\n",
    "nlp = English()\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "#CHANGE THIS LINE TO CHANGE PATTERN\n",
    "patterns = [nlp.make_doc(name) for name in [\"fever\",\"cough\",\"taste\",\"smell\", \"chills\",\"breathe\"]]\n",
    "matcher.add(\"Names\", patterns)\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "totalTestMatches_April = list([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "numMatchesApril = 0\n",
    "date = '-04-2020'\n",
    "\n",
    "for i in range(0,30):\n",
    "    date2 = date\n",
    "    if (i < 9):\n",
    "        date2 = '0' + str(i+1) + date\n",
    "    else:\n",
    "        date2 = str(i+1) + date;\n",
    "    totalMatches = 0\n",
    "    condition = aprilDF['date'] == date2\n",
    "    for row in aprilDF[condition]['text']:\n",
    "        doc = nlp(row)\n",
    "        if (len(matcher(doc)) > 0 ):\n",
    "            totalMatches += 1\n",
    "            numMatchesApril += 1\n",
    "    totalTestMatches_April[i] = totalMatches / aprilDF[condition]['text'].size\n",
    "        \n",
    "        \n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(\"aprilDF took: \" + str(toc - tic) + \" seconds\" )\n",
    "print(\"aprilDF matches: \" + str(numMatchesApril))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate corr array for new pattern\n",
    "N = 30 #(total number of days)\n",
    "\n",
    "x = unitedAll\n",
    "y = totalTestMatches_April\n",
    "corrArrayFreq = list()\n",
    "for i in range(0,14,1):\n",
    "    productVSM = calcVSM(i, N, x, y)\n",
    "    corrArrayFreq.append((1/(N)) * ((sum(productVSM))/np.sqrt(np.var(x[i:i+N]) * np.var(y[:N]))))\n",
    "corrArrayFreq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the combined US and UK against results for the keyword matching\n",
    "sample_range = 30\n",
    "x = subDates[:sample_range]\n",
    "y = totalTestMatches_April[:sample_range]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y, 's-r', label = \"Frequency\")\n",
    "\n",
    "ax.set_ylim(ymin=0)\n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(case_data[:sample_range], 'o-b', label = \"Number of new cases\")\n",
    "ax3.set_ylim(ymin=0)\n",
    "ax.xaxis.set_label_text(\"Date\")\n",
    "ax.yaxis.set_label_text(\"% of tweets matching pattern\")\n",
    "ax3.yaxis.set_label_text(\"Number of cases\")\n",
    "lns = [ax, ax3]\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax3.legend(loc='lower right', bbox_to_anchor=(1.0, 0.1))\n",
    "fig.subplots_adjust(right=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the NCC for the data against a time lag\n",
    "x = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "y = corrArrayFreq\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y, 's-r', label = \"NCC\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.xaxis.set_label_text(\"Offset (days)\")\n",
    "ax.yaxis.set_label_text(\"Correlation ratio\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
